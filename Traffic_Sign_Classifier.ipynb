{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \"traffic-signs-data/train.p\"\n",
    "validation_file= \"traffic-signs-data/valid.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Basic Summary of the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "#number of validation examples\n",
    "n_valid = len(X_valid)\n",
    "\n",
    "# number of testing examples\n",
    "n_test = len(X_test)\n",
    "\n",
    "# shape of a traffic sign image\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# number of unique classes/labels in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Show a sample traffic sign image chosen randomly from training data\n",
    "rand_n = np.random.randint(0, n_train)\n",
    "plt.imshow(X_train[rand_n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Show the 43 classes of traffic signs\n",
    "\n",
    "plt.figure(figsize= (18, 18))\n",
    "for i in range(0, n_classes):\n",
    "    plt.subplot(9, 5, i + 1) # set the rows and columns to show the plots\n",
    "    X_selected = X_train[y_train == i]\n",
    "    plt.imshow(X_selected[0,]) # show the first instance of each label\n",
    "    plt.title(i)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of traffic sign counts\n",
    "\n",
    "unique_val, unique_count = np.unique(y_train, return_counts = True)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.bar(unique_val, unique_count)\n",
    "plt.title(\"Distribution of Traffic Signs (Train Set)\")\n",
    "plt.xlabel(\"Traffic Sign #\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(np.arange(min(y_train), max(y_train) + 1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify classes that have relatively small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Classes with less than (low_count_limit) images\n",
    "low_count_limit = 500\n",
    "unique_classes, freq_classes = np.unique(y_train, return_counts = True)\n",
    "unique = dict(zip(unique_val, unique_count))\n",
    "low_unique = {k: v for k, v in unique.items() if v < low_count_limit}\n",
    "#low_unique.keys()\n",
    "low_class_list = sorted(list(low_unique.keys()))\n",
    "print(low_class_list)\n",
    "print(\"Number of classes below the limit:\", len(low_class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# augment data to have at least (low_count_limit) images for all classes\n",
    "for low_class in low_class_list:\n",
    "    print(low_class, \": \", end = \"\")\n",
    "    count_low_class = low_unique[low_class]\n",
    "    class_index_list = list(np.where(y_train == low_class))\n",
    "    for i in range(low_count_limit - count_low_class):\n",
    "        rand_angle = randint(-20, 20)\n",
    "        new_img = X_train[class_index_list[0][i % count_low_class]]\n",
    "        new_img = rotate(new_img, rand_angle, mode = \"edge\")\n",
    "        X_train = np.concatenate((X_train, [new_img]))\n",
    "        y_train = np.concatenate((y_train, [low_class]))\n",
    "        if i == (low_count_limit - count_low_class - 1):\n",
    "            print(\"|\") # print if done\n",
    "        elif i == 0:\n",
    "            pass\n",
    "        elif (i/(low_count_limit - count_low_class)*100) % 10 == 0: #print progress bar for every 10% complete\n",
    "            print(\"#\", end = \"\")\n",
    "    print()\n",
    "print(\"Number of new images added =\", len(X_train) - n_train)  \n",
    "print(\"Number of total images =\", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of traffic sign counts with augmented data added\n",
    "\n",
    "unique_val, unique_count = np.unique(y_train, return_counts = True)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.bar(unique_val, unique_count)\n",
    "plt.title(\"Distribution of Traffic Signs (Train Set with augmented data)\")\n",
    "plt.xlabel(\"Traffic Sign #\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(np.arange(min(y_train), max(y_train) + 1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 3: Design and Test a Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# function to grayscale image\n",
    "def grayscale(img):\n",
    "    img = np.array(img, dtype = np.float32)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_expanded = img[:, :, np.newaxis]\n",
    "    return img_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Shuffle the training data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to run all pre-processing\n",
    "def pre_process(img):\n",
    "    if grayscale_img:\n",
    "        img = grayscale(img)\n",
    "    if normalize_img:\n",
    "        img = (img - [128]) / 128\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set pre-processing options\n",
    "grayscale_img = True\n",
    "normalize_img = True\n",
    "\n",
    "# apply pre-processing\n",
    "X_train = np.array([pre_process(image) for image in X_train])\n",
    "X_valid = np.array([pre_process(image) for image in X_valid])\n",
    "X_test = np.array([pre_process(image) for image in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "dropout = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### LeNet-5 Architecture\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "\n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Input 14x14x6. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Layer 3: Convolutional. Input 10x10x16. Output = 6x6x64.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 64), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(64))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # Pooling. Input = 6x6x64. Output = 3x3x64.\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 3x3x64. Output = 576.\n",
    "    fc0   = flatten(conv3)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 576. Output = 240.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(576, 240), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(240))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "    # Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Dropout\n",
    "    fc1d = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 240. Output = 168.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 168), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(168))\n",
    "    fc2    = tf.matmul(fc1d, fc2_W) + fc2_b\n",
    "\n",
    "    # Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Dropout\n",
    "    fc2d = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # Layer 6: Fully Connected. Input = 168. Output = 84.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(168, 84), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(84))\n",
    "    fc3    = tf.matmul(fc2d, fc3_W) + fc3_b\n",
    "\n",
    "    # Activation.\n",
    "    fc3    = tf.nn.relu(fc3)\n",
    "    \n",
    "    # Dropout\n",
    "    fc3d = tf.nn.dropout(fc3, keep_prob)\n",
    "\n",
    "    # Layer 7: Fully Connected. Input = 84. Output = 43.\n",
    "    fc4_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc4_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc3d, fc4_W) + fc4_b\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1)) # placeholder for a batch of input images\n",
    "y = tf.placeholder(tf.int32, (None)) # placeholder for a batch of output labels\n",
    "keep_prob = tf.placeholder(tf.float32) # placeholder for dropout\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rate = 0.0005\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset + BATCH_SIZE], y_data[offset:offset + BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y , keep_prob: 1.})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valid_acc_list = []\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train) # shuffle training set before each epcoh\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        \n",
    "        # code to show loss plot\n",
    "        train_loss = sess.run(loss_operation, feed_dict={x: X_train, y: y_train, keep_prob: 1.})\n",
    "        valid_loss = sess.run(loss_operation, feed_dict={x: X_valid, y: y_valid, keep_prob: 1.})\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        \n",
    "        # code to show accuracy plot\n",
    "        training_accuracy = evaluate(X_train, y_train)\n",
    "        train_acc_list.append(training_accuracy)\n",
    "        validation_accuracy = evaluate(X_valid, y_valid) # measure the loss and accuracy of the validation set after each epoch\n",
    "        valid_acc_list.append(validation_accuracy)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    print()\n",
    "    print(\"Epoch:\", EPOCHS, \"Batch:\", BATCH_SIZE, \"Dropout:\", dropout, \"Rate:\", rate)\n",
    "\n",
    "    # show loss plot\n",
    "    plt.plot(train_loss_list, label=\"training\")\n",
    "    plt.plot(valid_loss_list, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"loss\")\n",
    "    plt.show()\n",
    "\n",
    "    # show accuracy plot\n",
    "    plt.plot(train_acc_list, label=\"training\")\n",
    "    plt.plot(valid_acc_list, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    saver.save(sess, './lenet') # save the model after training\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model *(To be run after more tuning)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 4: Test a Model on New Images *(In progress)*\n",
    "\n",
    "Predicting the traffic sign type of German traffic signs downloaded from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 5: Visualize the Neural Network's State with Test Images *(In progress)*\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
